replay_size: &replay_size 200
gamma: 0.99
lr: &lr_val 3.0e-4
train_every: *replay_size
train_batches: 1
update_after: 1000
batch_size: *replay_size
value_coef: 0.5
entropy_coef: 0.01
max_grad_norm: 0.5
adam_eps: 1.0e-4

controller: 'DecentralizedController'
agent: 'ACRewardAgent'
true_reward: False
use_full_obs: False
device: 'cpu'
hidden_layers: &hidden [64, 64]

reward_hidden_layers: *hidden
N_predictors: 3
perturb_prob: 0.2
reward_lr: *lr_val

trajectory_length: 10
pairs_count: 32
similarity: 0.25
trajectory_database: 10000
reward_weighting: 0.5
other_value_coef: 0.1
#update_predictor_fraction: 0.2