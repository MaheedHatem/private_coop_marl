replay_size: &replay_size 100000
gamma: 0.9
lr: &lr_val 3.0e-4
train_every: 10
train_batches: 1
update_after: 10000
batch_size: 128
total_steps: 5000000
steps_per_epoch: 10000
random_steps_fraction: 0.5
init_epsilon: 1
final_epsilon: 0.1
target_update: 1
target_update_every: 500

controller: 'DecentralizedController'
agent: 'DQNRewardAgent'
true_reward: False
use_full_obs: False
device: 'cpu'

env_name_index: 3
N_agents: 2
grid_size: 12
env_args: 
  max_episode_steps: 25
max_food: 2
hidden_layers: [64, 64]
eval_episodes: 2
render_last_episode: False

reward_hidden_layers: [64,64]
N_predictors: 3
perturb_prob: 0.0
reward_lr: *lr_val

trajectory_length: 10
pairs_count: 32
similarity: 0.25
reward_weighting: 0.5
trajectory_database: *replay_size
trajectory_buffer_ratio: 10
